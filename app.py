import streamlit as st
import sqlite3
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo
import os
import re
import json
import io
import hashlib
import google.generativeai as genai

# ---------- File parsing ----------
import pypdf
from docx import Document
from pptx import Presentation
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# =====================================================
# DB
# =====================================================

DB_FILE = "pk_study_log.db"

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute("""
    CREATE TABLE IF NOT EXISTS materials (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT,
        file_hash TEXT UNIQUE,
        uploaded_at TEXT
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS questions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        material_id INTEGER,
        topic TEXT,
        question TEXT,
        choices_json TEXT,
        correct TEXT,
        explanation TEXT
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS students (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        student_key TEXT UNIQUE
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS answers (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        student_id INTEGER,
        question_id INTEGER,
        is_correct INTEGER,
        answered_at TEXT,
        misconception_note TEXT
    )
    """)

    def ensure_misconception_column():
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("PRAGMA table_info(answers)")
        cols = [row[1] for row in c.fetchall()]
        if "misconception_note" not in cols:
            c.execute("ALTER TABLE answers ADD COLUMN misconception_note TEXT")
            conn.commit()
        conn.close()


    conn.commit()
    conn.close()
    ensure_misconception_column()

def calc_file_hash(data: bytes) -> str:
    return hashlib.sha256(data).hexdigest()

def get_or_create_material(file_name: str, data: bytes):
    file_hash = calc_file_hash(data)

    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute(
        "SELECT id FROM materials WHERE file_hash = ?",
        (file_hash,)
    )
    row = c.fetchone()

    if row:
        material_id = row[0]
    else:
        c.execute(
            "INSERT INTO materials (title, file_hash, uploaded_at) VALUES (?, ?, ?)",
            (
                file_name,
                file_hash,
                datetime.now(ZoneInfo("Asia/Tokyo")).isoformat()
            )
        )
        material_id = c.lastrowid
        conn.commit()

    conn.close()
    return material_id


def log_answer(student_id, question_id, is_correct, misconception_note=None):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute("""
    INSERT INTO answers
    (student_id, question_id, is_correct, answered_at, misconception_note)
    VALUES (?, ?, ?, ?, ?)
    """, (
        student_id,
        question_id,
        int(is_correct),
        datetime.now(ZoneInfo("Asia/Tokyo")).isoformat(),
        misconception_note
    ))

    conn.commit()
    conn.close()

    
def get_stats(student_id):
    conn = sqlite3.connect(DB_FILE)
    df = pd.read_sql("""
        SELECT
            a.id,
            q.topic,
            a.is_correct
        FROM answers a
        JOIN questions q ON a.question_id = q.id
        WHERE a.student_id = ?
    """, conn, params=(student_id,))
    conn.close()
    return df


# =====================================================
# Gemini
# =====================================================

def configure_gemini():
    api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    genai.configure(api_key=api_key)
    return True


# =====================================================
# File extraction
# =====================================================
def chunk_text(text, size=500, overlap=100):
    if overlap >= size:
        raise ValueError("overlap must be smaller than size")

    chunks = []
    start = 0
    while start < len(text):
        end = start + size
        chunks.append(text[start:end])
        start += size - overlap
    return chunks


def retrieve_relevant_chunks(chunks, query, top_k=3):
    if not chunks:
        return []

    vec = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b", max_df=0.9)
    X = vec.fit_transform(chunks + [query])
    sims = cosine_similarity(X[-1], X[:-1])[0]
    idx = sims.argsort()[-top_k:][::-1]
    return [chunks[i] for i in idx]



def extract_from_pdf(data):
    reader = pypdf.PdfReader(io.BytesIO(data))
    texts = []
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            texts.append(f"ã€ãƒšãƒ¼ã‚¸ {i+1}ã€‘\n{text}")
    return "\n\n".join(texts)

def extract_from_docx(data):
    doc = Document(io.BytesIO(data))
    texts = []
    for p in doc.paragraphs:
        if p.style.name.startswith("Heading"):
            texts.append(f"\n## {p.text}\n")
        else:
            texts.append(p.text)
    return "\n".join(texts)

def extract_from_xlsx(data):
    xl = pd.ExcelFile(io.BytesIO(data))
    texts = []
    for sheet in xl.sheet_names:
        df = xl.parse(sheet)
        texts.append(f"\n## ã‚·ãƒ¼ãƒˆ: {sheet}\n")
        texts.append(df.to_csv(index=False))
    return "\n".join(texts)

def extract_from_pptx(data):
    prs = Presentation(io.BytesIO(data))
    texts = []
    for i, slide in enumerate(prs.slides):
        texts.append(f"\n## ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1}\n")
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                texts.append(shape.text)
    return "\n".join(texts)

def extract_text_from_bytes(data: bytes, filename: str):
    ext = filename.split(".")[-1].lower()

    if ext == "pdf":
        return extract_from_pdf(data)
    if ext == "docx":
        return extract_from_docx(data)
    if ext == "xlsx":
        return extract_from_xlsx(data)
    if ext == "pptx":
        return extract_from_pptx(data)

    raise ValueError("æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")



# =====================================================
# AI problem generation
# =====================================================

def safe_json_load(text: str):
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é™¤å»
    text = re.sub(r"```(?:json)?", "", text).replace("```", "").strip()

    # 1. ãã®ã¾ã¾è©¦è¡Œ
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    # 2. ç¯„å›²æŠ½å‡º
    start_candidates = [i for i in [text.find("{"), text.find("[")] if i != -1]
    if not start_candidates:
        raise ValueError(f"JSONãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n\n--- Geminiå‡ºåŠ› ---\n{text}")

    start = min(start_candidates)
    end_obj = text.rfind("}")
    end_arr = text.rfind("]")
    end = max(end_obj, end_arr)

    # é–‰ã˜ã‚«ãƒƒã‚³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€æ–‡å­—åˆ—ã®æœ€å¾Œã¾ã§ã‚’å¯¾è±¡ã¨ã™ã‚‹
    if end == -1 or end <= start:
        json_text = text[start:].strip()
    else:
        json_text = text[start:end + 1].strip()

    # 3. è§£æã‚’è©¦ã¿ã€å¤±æ•—ã—ãŸã‚‰é–‰ã˜ã‚«ãƒƒã‚³ã‚’è£œå®Œã—ã¦ãƒªãƒˆãƒ©ã‚¤
    try:
        return json.loads(json_text)
    except json.JSONDecodeError:
        try:
            # å¼·å¼•ã«é–‰ã˜ã‚«ãƒƒã‚³ã‚’ä»˜ã‘è¶³ã—ã¦ã¿ã‚‹ï¼ˆå˜ç´”ãªç”Ÿæˆä¸­æ–­å¯¾ç­–ï¼‰
            return json.loads(json_text + "}")
        except:
            try:
                return json.loads(json_text + "]}") # ãƒã‚¹ãƒˆå¯¾ç­–
            except:
                raise ValueError(f"JSONè§£æå¤±æ•—: æ§‹é€ ãŒå£Šã‚Œã¦ã„ã¾ã™ã€‚\n\n--- æŠ½å‡ºJSON ---\n{json_text}")

def generate_one_ai_problem(text, problem_no):
    model = genai.GenerativeModel("gemini-2.5-flash-lite")

    prompt = f"""
ä»¥ä¸‹ã®è³‡æ–™ã‚’ã‚‚ã¨ã«ã€è–¬å‰¤å¸«å›½å®¶è©¦é¨“å½¢å¼ã®äº”è‚¢æŠä¸€å•é¡Œã‚’1å•ä½œæˆã—ã¦ãã ã•ã„ã€‚


ã€é‡è¦ã€‘
ã“ã‚Œã¯ã€{problem_no}å•ç›®ã€‘ã§ã™ã€‚
ã“ã‚Œã¾ã§ã¨ã¯ç•°ãªã‚‹è«–ç‚¹ãƒ»æ¦‚å¿µãƒ»çŸ¥è­˜ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
åŒã˜å•é¡Œãƒ»é¡ä¼¼å•é¡Œã¯ç¦æ­¢ã§ã™ã€‚

ã€æ¡ä»¶ã€‘â€»å¿…ãšå³å®ˆã™ã‚‹ã“ã¨
ãƒ»5æŠå˜ä¸€æ­£è§£
ãƒ»choices ã¯ Aã€œE ã®5ã¤ã™ã¹ã¦ã‚’å«ã‚ã‚‹
ãƒ»æ­£è§£ã¯å¿…ãš "correct" ã‚­ãƒ¼ã§å‡ºåŠ›ã™ã‚‹ï¼ˆAã€œE ã®1æ–‡å­—ï¼‰
ãƒ»è§£èª¬ã¯å¿…ãš "explanation" ã‚­ãƒ¼ã§å‡ºåŠ›ã™ã‚‹ï¼ˆ1ã€œ3æ–‡ï¼‰
ãƒ»JSONä»¥å¤–ã®æ–‡ç« ã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„

å‡ºåŠ›å½¢å¼:
{{
  "topic": "åˆ†é‡å",
  "question": "å•é¡Œæ–‡",
  "choices": {{
    "A": "é¸æŠè‚¢",
    "B": "é¸æŠè‚¢",
    "C": "é¸æŠè‚¢",
    "D": "é¸æŠè‚¢",
    "E": "é¸æŠè‚¢"
  }},
  "correct": "A",
  "explanation": "è§£èª¬"
}}

è³‡æ–™ï¼ˆé–¢é€£éƒ¨åˆ†ã®ã¿ï¼‰:
{text}
"""

    response = model.generate_content(
        prompt,
        generation_config={
            "temperature": 0.1,
            "max_output_tokens": 500
        }
    )

    if not response.candidates:
        raise ValueError("GeminiãŒå¿œç­”ã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸ")

    c = response.candidates[0]
    if not c.content or not c.content.parts:
        raise ValueError(f"Geminiå‡ºåŠ›ãŒç©ºã§ã™ (finish_reason={c.finish_reason})")

    raw = c.content.parts[0].text
    data = safe_json_load(raw)

    # GeminiãŒé…åˆ—ã§è¿”ã—ã¦ããŸå ´åˆã«ã‚‚å¯¾å¿œ
    if isinstance(data, list):
        if not data:
            raise ValueError("GeminiãŒç©ºé…åˆ—ã‚’è¿”ã—ã¾ã—ãŸ")
        return data[0]

    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§è¿”ã—ã¦ããŸå ´åˆ
    return data

    
def generate_ai_problems(text, n=3):
    problems = []
    for i in range(n):
        p = generate_one_ai_problem(text, i + 1)
        problems.append(p)
    return problems

def generate_misconception_note(
    topic: str,
    question: str,
    choices: dict,
    correct: str,
    selected: str
) -> str | None:
    """
    èª¤ç­”æ™‚ã®ã€Œå­¦å•çš„ã¤ã¾ãšãã®ç¤ºå”†ã€ã‚’1æ–‡ã§ç”Ÿæˆ
    â€» å†…éƒ¨ãƒ­ã‚°å°‚ç”¨ï¼ˆå­¦ç”Ÿéè¡¨ç¤ºï¼‰
    """
    model = genai.GenerativeModel("gemini-2.5-flash-lite")

    prompt = f"""
ä»¥ä¸‹ã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“å½¢å¼ã®å•é¡Œã§ã™ã€‚

åˆ†é‡: {topic}
å•é¡Œæ–‡:
{question}

é¸æŠè‚¢:
{json.dumps(choices, ensure_ascii=False)}

æ­£è§£: {correct}
å­¦ç”Ÿã®é¸æŠ: {selected}

ã“ã®èª¤ç­”ã‹ã‚‰è€ƒãˆã‚‰ã‚Œã‚‹
ã€Œå­¦ç¿’ä¸Šã®ã¤ã¾ãšãã€ã‚’
ã€1æ–‡ã®ã¿ã€‘ã§è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
ãƒ»æ–­å®šã¯ç¦æ­¢
ãƒ»ã€Œã€œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€ãªã©å¯èƒ½æ€§è¡¨ç¾ã‚’ç”¨ã„ã‚‹
ãƒ»è©•ä¾¡ãƒ»å±è²¬ãƒ»è¨ºæ–­èªã¯ç¦æ­¢
ãƒ»å­¦å•çš„å†…å®¹ã«é™å®šã™ã‚‹
"""

    try:
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.2,
                "max_output_tokens": 100
            }
        )
        text = response.text.strip()
        if text:
            return text
    except Exception:
        pass

    return None

   
def get_ai_coaching_message(df, recent_n=5):
    """
    5å•ã”ã¨ã®é€šå¸¸ã‚³ãƒ¼ãƒãƒ³ã‚°
    ãƒ»ã‚ˆãã‚ã‚‹èª¤è§£
    ãƒ»æš—è¨˜ã‹ç†è§£ã‹ã‚’æ˜ç¤º
    """
    if df.empty:
        return ""

    # --- ç´¯ç©çµ±è¨ˆ ---
    total_stats = df.groupby("topic").agg(
        æ­£è§£æ•°=("is_correct", "sum"),
        å›ç­”æ•°=("id", "count")
    )
    total_stats["æ­£ç­”ç‡"] = total_stats["æ­£è§£æ•°"] / total_stats["å›ç­”æ•°"]

    # --- ç›´è¿‘ n å• ---
    recent_df = df.tail(recent_n)
    recent_stats = recent_df.groupby("topic").agg(
        æ­£è§£æ•°=("is_correct", "sum"),
        å›ç­”æ•°=("id", "count")
    )
    recent_stats["æ­£ç­”ç‡"] = recent_stats["æ­£è§£æ•°"] / recent_stats["å›ç­”æ•°"]

    prompt = f"""
ã‚ãªãŸã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã®å­¦ç¿’ã‚’æ”¯æ´ã™ã‚‹ã‚³ãƒ¼ãƒã§ã™ã€‚

ä»¥ä¸‹ã¯ã€ç›´è¿‘{recent_n}å•ã€‘ã®åˆ†é‡åˆ¥æˆç¸¾ã§ã™ã€‚
{recent_stats.to_csv()}

ä»¥ä¸‹ã¯ã€ã“ã‚Œã¾ã§å…¨ä½“ã€‘ã®åˆ†é‡åˆ¥æˆç¸¾ã§ã™ã€‚
{total_stats.to_csv()}

ã“ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€
ãƒ»ç›´è¿‘ã§ç›®ç«‹ã£ãŸèª¤è§£ã‚„æ··åŒã—ã‚„ã™ã„ãƒã‚¤ãƒ³ãƒˆ
ãƒ»ãã®åˆ†é‡ã¯ã€Œæš—è¨˜é‡è¦–ã€ã‹ã€Œç†è§£é‡è¦–ã€ã‹
ã‚’ä¸­å¿ƒã«ã€ç©ã‚„ã‹ãªã‚³ãƒ¼ãƒå£èª¿ã§ç°¡æ½”ã«è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€æ³¨æ„ã€‘
ãƒ»å±è²¬ã¯ç¦æ­¢
ãƒ»å‰å‘ããªåŠ©è¨€ã«ã™ã‚‹
ãƒ»æŒ¨æ‹¶æ–‡ã¯ä¸è¦
"""

    model = genai.GenerativeModel("gemini-2.5-flash-lite")
    response = model.generate_content(
        prompt,
        generation_config={"temperature": 0.2, "max_output_tokens": 600}
    )

    return response.text

def get_ai_final_coaching_message(df):
    """
    å…¨å•çµ‚äº†æ™‚ã®æœ€çµ‚ã‚³ãƒ¼ãƒãƒ³ã‚°
    ãƒ»æ•°å€¤ã‚’æ˜ç¤º
    ãƒ»æˆé•·ã‚’è¨€èªåŒ–
    ãƒ»ç¶™ç¶šã®å‹•æ©Ÿã¥ã‘
    """
    if df.empty:
        return ""

    total_answered = len(df)
    total_correct = df["is_correct"].sum()
    total_rate = total_correct / total_answered

    stats = df.groupby("topic").agg(
        æ­£è§£æ•°=("is_correct", "sum"),
        å›ç­”æ•°=("id", "count")
    )
    stats["æ­£ç­”ç‡"] = stats["æ­£è§£æ•°"] / stats["å›ç­”æ•°"]

    prompt = f"""
ã‚ãªãŸã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã®å­¦ç¿’ã‚’æ”¯æ´ã™ã‚‹ã‚³ãƒ¼ãƒã§ã™ã€‚

ä»¥ä¸‹ã¯ã€ã‚ã‚‹å­¦ç”Ÿã®ä»Šå›ã®å­¦ç¿’çµæœã§ã™ã€‚

ãƒ»ç·å›ç­”æ•°: {total_answered}
ãƒ»æ­£è§£æ•°: {total_correct}
ãƒ»æ­£ç­”ç‡: {total_rate:.0%}

åˆ†é‡åˆ¥æˆç¸¾:
{stats.to_csv()}

ã“ã®çµæœã‚’ã‚‚ã¨ã«ã€
ãƒ»ä»Šå›ã—ã£ã‹ã‚Šå–ã‚Šçµ„ã‚ãŸç‚¹
ãƒ»ç†è§£ãŒå®šç€ã—ã¦ãã¦ã„ã‚‹åˆ†é‡
ãƒ»åŠªåŠ›ãŒæˆæœã«ã¤ãªãŒã£ã¦ã„ã‚‹ç‚¹
ã‚’å…·ä½“çš„ã«ç¤ºã—ã€å­¦ç¿’ç¶™ç¶šã®æ„æ¬²ãŒé«˜ã¾ã‚‹ã‚ˆã†ãª
å‰å‘ãã§ç©ã‚„ã‹ãªã‚³ãƒ¼ãƒãƒ³ã‚°ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚

ã€æ³¨æ„ã€‘
ãƒ»å±è²¬ã‚„å¦å®šã¯ç¦æ­¢
ãƒ»æ¯”è¼ƒã¯ç¦æ­¢
ãƒ»æŒ¨æ‹¶æ–‡ã¯ä¸è¦
"""

    model = genai.GenerativeModel("gemini-2.5-flash-lite")
    response = model.generate_content(
        prompt,
        generation_config={"temperature": 0.3, "max_output_tokens": 700}
    )

    return response.text

   



# =====================================================
# UI
# =====================================================
student_key = st.text_input("å­¦ç±ç•ªå·ã¾ãŸã¯ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ")
def normalize_problem(p: dict) -> dict:
    required = ["topic", "question", "choices", "correct", "explanation"]
    missing = [k for k in required if k not in p]

    if missing:
        raise ValueError(f"å¿…é ˆã‚­ãƒ¼ä¸è¶³: {missing}")

    if not isinstance(p["choices"], dict) or len(p["choices"]) != 5:
        raise ValueError("choices ãŒä¸æ­£ã§ã™")

    if p["correct"] not in p["choices"]:
        raise ValueError("correct ãŒ choices ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    return p



def get_or_create_student(student_key):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute(
        "SELECT id FROM students WHERE student_key = ?",
        (student_key,)
    )
    row = c.fetchone()

    if row:
        student_id = row[0]
    else:
        c.execute(
            "INSERT INTO students (student_key) VALUES (?)",
            (student_key,)
        )
        student_id = c.lastrowid
        conn.commit()

    conn.close()
    return student_id

def delete_questions_by_material(material_id):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute(
        "DELETE FROM questions WHERE material_id = ?",
        (material_id,)
    )

    conn.commit()
    conn.close()

    
def save_questions(material_id, problems):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    valid_count = 0

    for p in problems:
        try:
            p = normalize_problem(p)
        except Exception as e:
            st.warning(f"âš ï¸ ä¸æ­£ãªå•é¡Œã‚’é™¤å¤–ã—ã¾ã—ãŸ: {e}")
            continue

        c.execute("""
        INSERT INTO questions
        (material_id, topic, question, choices_json, correct, explanation)
        VALUES (?, ?, ?, ?, ?, ?)
        """, (
            material_id,
            p["topic"],
            p["question"],
            json.dumps(p["choices"], ensure_ascii=False),
            p["correct"],
            p["explanation"]
        ))
        valid_count += 1

    conn.commit()
    conn.close()

    if valid_count == 0:
        raise ValueError("æœ‰åŠ¹ãªå•é¡ŒãŒ1å•ã‚‚ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


    
def main():
    st.set_page_config("AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª", layout="centered")
    st.title("ğŸ“š AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª")

    init_db()
    if not configure_gemini():
        return

    if "text" not in st.session_state:
        st.session_state.text = None
    if "problems" not in st.session_state:
        st.session_state.problems = []
    if "idx" not in st.session_state:
        st.session_state.idx = 0
    if "answered_idx" not in st.session_state:
        st.session_state.answered_idx = {}
    if "is_correct_idx" not in st.session_state:
        st.session_state.is_correct_idx = {}


    tab1, tab2, tab3 = st.tabs(["è³‡æ–™", "å•é¡Œæ¼”ç¿’", "ã‚³ãƒ¼ãƒãƒ³ã‚°"])

    # ---------- è³‡æ–™ ----------
    with tab1:
        file = st.file_uploader(
            "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "pptx"]
        )

        if file:
            with st.spinner("è³‡æ–™è§£æä¸­..."):
                data = file.read()

                material_id = get_or_create_material(file.name, data)
                st.session_state.material_id = material_id

                st.session_state.text = extract_text_from_bytes(data, file.name)

            st.success("è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")


            if st.button("AIå•é¡Œã‚’ç”Ÿæˆ"):
                try:
                    with st.spinner("å•é¡Œç”Ÿæˆä¸­..."):
                        if "material_id" not in st.session_state:
                            st.error("è³‡æ–™ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                            return

                        chunks = chunk_text(st.session_state.text)

                        retrieved = retrieve_relevant_chunks(
                            chunks,
                            query="è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã®äº”è‚¢æŠä¸€å•é¡Œã‚’ä½œæˆã™ã‚‹"
)

                        context = "\n\n".join(retrieved)

                        problems = generate_ai_problems(context)

                        
                        if not problems:
                            raise ValueError("å•é¡ŒãŒ1å•ã‚‚ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆGeminiå‡ºåŠ›/JSONè§£æå¤±æ•—ã®å¯èƒ½æ€§ï¼‰")

                       
                        # â‘  DBä¿å­˜
                        save_questions(st.session_state.material_id, problems)
                        # â‘¡ DBã‹ã‚‰èª­ã¿ç›´ã™
                        conn = sqlite3.connect(DB_FILE, timeout=30, check_same_thread=False)
                        df = pd.read_sql(
                            """
                            SELECT * FROM questions
                            WHERE material_id = ?
                            ORDER BY id
                            """,
                            conn,
                            params=(st.session_state.material_id,)
                        )
                        conn.close()
                        # â‘¢ session_state ã«å…¥ã‚Œã‚‹
                        st.session_state.problems = df.to_dict("records")
                                         
                    st.session_state.idx = 0
                    st.session_state.answered = False
                    st.session_state.answered_idx = {}
                    st.session_state.is_correct_idx = {}
                    st.success("å•é¡Œã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                    st.rerun()

                except Exception as e:
                    st.error("âŒ å•é¡Œç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    st.exception(e)
     
    # ---------- å•é¡Œ ----------
    with tab2:
        if not student_key:
            st.warning("å­¦ç±ç•ªå·ã¾ãŸã¯ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()

        # --- idx ã®å®‰å…¨åŒ– ---
        if st.session_state.idx < 0:
            st.session_state.idx = 0

        
        if not st.session_state.problems and "material_id" in st.session_state:
            conn = sqlite3.connect(DB_FILE)
            df = pd.read_sql(
                """
                SELECT * FROM questions
                WHERE material_id = ?
                ORDER BY id
                """,
                conn,
                params=(st.session_state.material_id,)
            )
            conn.close()
            st.session_state.problems = df.to_dict("records")
            
        if not st.session_state.problems:
            st.info("å•é¡ŒãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
            st.stop()

    # --- å…¨å•çµ‚äº† ---
        if st.session_state.problems and st.session_state.idx >= len(st.session_state.problems):
            st.success("ğŸ‰ ã™ã¹ã¦ã®å•é¡ŒãŒçµ‚äº†ã—ã¾ã—ãŸï¼")
            
            student_id = get_or_create_student(student_key)
            df = get_stats(student_id)
            
            correct = sum(st.session_state.is_correct_idx.values())
            total = len(st.session_state.problems)
            st.write(f"æ­£è§£æ•°: {correct} / {total}")

            if st.button("ã‚‚ã†ä¸€åº¦æœ€åˆã‹ã‚‰"):
                st.session_state.idx = 0
                st.rerun()
            return
            
         # --- å•é¡Œè¡¨ç¤º ---
        p = st.session_state.problems[st.session_state.idx]
        st.subheader(f"å•é¡Œ {st.session_state.idx + 1}")
        st.markdown(p["question"])

        # --- choices ã‚’ dict ã«å¤‰æ›ï¼ˆ1å•åˆ†ï¼‰ ---
        choices = json.loads(p["choices_json"])

        choice = st.radio(
            "é¸æŠè‚¢",
            options=list(choices.keys()),
            format_func=lambda x: f"{x}: {choices[x]}",
            key=f"choice_{p['id']}"
        )


        # --- è§£ç­”ã™ã‚‹ ---
        answered = st.session_state.answered_idx.get(st.session_state.idx, False)
        if not answered:
            if st.button("è§£ç­”ã™ã‚‹"):
                st.session_state.answered_idx[st.session_state.idx] = True

                is_correct = (choice == p["correct"])
                st.session_state.is_correct_idx[st.session_state.idx] = is_correct

                student_id = get_or_create_student(student_key)

            # --- èª¤ç­”æ™‚ã®ã¿å­¦å•çš„ç¤ºå”†ã‚’ç”Ÿæˆ ---
                misconception_note = None
                if not is_correct:
                    misconception_note = generate_misconception_note(
                        topic=p["topic"],
                        question=p["question"],
                        choices=json.loads(p["choices_json"]),
                        correct=p["correct"],
                        selected=choice
                    )

                log_answer(
                    student_id,
                    p["id"],
                    is_correct,
                    misconception_note
                )

                st.rerun()




        # --- è§£ç­”å¾Œè¡¨ç¤º ---
        answered = st.session_state.answered_idx.get(st.session_state.idx, False)
        
        if answered:
            is_correct = st.session_state.is_correct_idx.get(st.session_state.idx, False)

            if is_correct:
                st.success("æ­£è§£ã§ã™ ğŸ‰")
            else:
                st.error(f"ä¸æ­£è§£ã§ã™ã€‚æ­£è§£ã¯ {p['correct']} ã§ã™ã€‚")
                
            # --- è§£èª¬ ---
            st.markdown("### è§£èª¬")
            st.markdown(p["explanation"])

            # --- è§£ç­”æ•° ---
            answered_count = len(st.session_state.is_correct_idx)

            student_id = get_or_create_student(student_key)
            df = get_stats(student_id)

            # ===== 5å•ã”ã¨ã®é€šå¸¸ã‚³ãƒ¼ãƒãƒ³ã‚° =====
            if answered_count > 0 and answered_count % 5 == 0 and answered_count < len(st.session_state.problems):
                st.markdown("---")
                st.markdown("### ğŸ” ä»Šå›ã®5å•ã®æŒ¯ã‚Šè¿”ã‚Š")
                msg = get_ai_coaching_message(df, recent_n=5)
                st.info(msg)

            # ===== æœ€å¾Œã®ç§°è³›ã‚³ãƒ¼ãƒãƒ³ã‚° =====
            if answered_count == len(st.session_state.problems):
                st.markdown("---")
                st.markdown("### ğŸ‰ ä»Šå›ã®å­¦ç¿’ã®ã¾ã¨ã‚")
                final_msg = get_ai_final_coaching_message(df)
                st.success(final_msg)

            
            # --- æ¬¡ã®å•é¡Œã¸ ---
            if st.button("æ¬¡ã®å•é¡Œã¸"):
                st.session_state.idx += 1
                st.rerun()


    # ---------- ã‚³ãƒ¼ãƒãƒ³ã‚° ----------
    with tab3:
        student_id = get_or_create_student(student_key)
        df = get_stats(student_id)
        if df.empty:
            st.info("å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.subheader("åˆ†é‡åˆ¥ æ­£ç­”ç‡")
            stats = df.groupby("topic").agg(
                æ­£è§£æ•°=("is_correct", "sum"),
                å›ç­”æ•°=("id", "count")
            )
            stats["æ­£ç­”ç‡"] = stats["æ­£è§£æ•°"] / stats["å›ç­”æ•°"]
            st.dataframe(stats, width="stretch")

            if st.button("AIã‚³ãƒ¼ãƒãƒ³ã‚°ã‚’æ›´æ–°"):
                with st.spinner("åˆ†æä¸­..."):
                    msg = get_ai_coaching_message(df)
                st.info(msg)


if __name__ == "__main__":
    main()
























































































