import streamlit as st
import sqlite3
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo
import os
import re
import json
import io
import hashlib
import requests

# ---------- File parsing ----------
import pypdf
from docx import Document
from pptx import Presentation
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# =====================================================
# Hugging Face / Gemma API
# =====================================================

def hf_generate(prompt: str, max_tokens=500, temperature=0.1) -> str:
    hf_token = st.secrets.get("HF_TOKEN") or os.getenv("HF_TOKEN")
    if not hf_token:
        raise RuntimeError("HF_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    API_URL = "https://api-inference.huggingface.co/models/google/gemma-3-4b-it"
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }

    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": max_tokens,
            "temperature": temperature,
            "return_full_text": False
        }
    }

    r = requests.post(API_URL, headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()

    if isinstance(data, list) and data and "generated_text" in data[0]:
        return data[0]["generated_text"]

    raise ValueError(f"Unexpected HF response: {data}")


# =====================================================
# DB
# =====================================================

DB_FILE = "pk_study_log.db"

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute("""
    CREATE TABLE IF NOT EXISTS materials (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT,
        file_hash TEXT UNIQUE,
        uploaded_at TEXT
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS questions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        material_id INTEGER,
        topic TEXT,
        question TEXT,
        choices_json TEXT,
        correct TEXT,
        explanation TEXT
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS students (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        student_key TEXT UNIQUE
    )
    """)

    c.execute("""
    CREATE TABLE IF NOT EXISTS answers (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        student_id INTEGER,
        question_id INTEGER,
        is_correct INTEGER,
        answered_at TEXT,
        misconception_note TEXT
    )
    """)

    conn.commit()
    conn.close()


def calc_file_hash(data: bytes) -> str:
    return hashlib.sha256(data).hexdigest()


def get_or_create_material(file_name: str, data: bytes):
    file_hash = calc_file_hash(data)

    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute("SELECT id FROM materials WHERE file_hash = ?", (file_hash,))
    row = c.fetchone()

    if row:
        material_id = row[0]
    else:
        c.execute(
            "INSERT INTO materials (title, file_hash, uploaded_at) VALUES (?, ?, ?)",
            (file_name, file_hash, datetime.now(ZoneInfo("Asia/Tokyo")).isoformat())
        )
        material_id = c.lastrowid
        conn.commit()

    conn.close()
    return material_id


def log_answer(student_id, question_id, is_correct, misconception_note=None):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    c.execute("""
    INSERT INTO answers
    (student_id, question_id, is_correct, answered_at, misconception_note)
    VALUES (?, ?, ?, ?, ?)
    """, (
        student_id,
        question_id,
        int(is_correct),
        datetime.now(ZoneInfo("Asia/Tokyo")).isoformat(),
        misconception_note
    ))

    conn.commit()
    conn.close()


def get_stats(student_id):
    conn = sqlite3.connect(DB_FILE)
    df = pd.read_sql("""
        SELECT
            a.id,
            q.topic,
            a.is_correct
        FROM answers a
        JOIN questions q ON a.question_id = q.id
        WHERE a.student_id = ?
    """, conn, params=(student_id,))
    conn.close()
    return df


# =====================================================
# JSON safety
# =====================================================

def safe_json_load(text: str):
    text = re.sub(r"```(?:json)?", "", text).replace("```", "").strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    start = min(i for i in [text.find("{"), text.find("[")] if i != -1)
    end = max(text.rfind("}"), text.rfind("]"))

    json_text = text[start:end + 1] if end > start else text[start:]

    try:
        return json.loads(json_text)
    except json.JSONDecodeError:
        raise ValueError(f"JSONè§£æå¤±æ•—\n---\n{json_text}")


# =====================================================
# AI generation (Gemma)
# =====================================================

def generate_one_ai_problem(text, problem_no):
    prompt = f"""
ä»¥ä¸‹ã®è³‡æ–™ã‚’ã‚‚ã¨ã«ã€è–¬å‰¤å¸«å›½å®¶è©¦é¨“å½¢å¼ã®äº”è‚¢æŠä¸€å•é¡Œã‚’1å•ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
ã“ã‚Œã¯ã€{problem_no}å•ç›®ã€‘ã§ã™ã€‚
ã“ã‚Œã¾ã§ã¨ã¯ç•°ãªã‚‹è«–ç‚¹ãƒ»æ¦‚å¿µãƒ»çŸ¥è­˜ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚

ã€æ¡ä»¶ã€‘â€»å¿…ãšå³å®ˆ
ãƒ»5æŠå˜ä¸€æ­£è§£
ãƒ»choices ã¯ Aã€œE
ãƒ»correct ã¯ Aã€œE
ãƒ»JSONä»¥å¤–å‡ºåŠ›ç¦æ­¢

å‡ºåŠ›å½¢å¼:
{{
  "topic": "...",
  "question": "...",
  "choices": {{
    "A": "...",
    "B": "...",
    "C": "...",
    "D": "...",
    "E": "..."
  }},
  "correct": "A",
  "explanation": "..."
}}

è³‡æ–™:
{text}
"""
    raw = hf_generate(prompt, max_tokens=500, temperature=0.1)
    data = safe_json_load(raw)
    return data[0] if isinstance(data, list) else data


def generate_misconception_note(topic, question, choices, correct, selected):
    prompt = f"""
ä»¥ä¸‹ã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“å½¢å¼ã®å•é¡Œã§ã™ã€‚

åˆ†é‡: {topic}
å•é¡Œæ–‡:
{question}

é¸æŠè‚¢:
{json.dumps(choices, ensure_ascii=False)}

æ­£è§£: {correct}
å­¦ç”Ÿã®é¸æŠ: {selected}

ã“ã®èª¤ç­”ã‹ã‚‰è€ƒãˆã‚‰ã‚Œã‚‹å­¦ç¿’ä¸Šã®ã¤ã¾ãšãã‚’
ã€1æ–‡ã®ã¿ã€‘ã§è¿°ã¹ã¦ãã ã•ã„ã€‚
"""
    try:
        return hf_generate(prompt, max_tokens=100, temperature=0.2).strip()
    except Exception:
        return None


def get_ai_coaching_message(df, recent_n=5):
    if df.empty:
        return ""

    total = df.groupby("topic").agg(æ­£è§£æ•°=("is_correct", "sum"), å›ç­”æ•°=("id", "count"))
    recent = df.tail(recent_n).groupby("topic").agg(æ­£è§£æ•°=("is_correct", "sum"), å›ç­”æ•°=("id", "count"))

    prompt = f"""
ã‚ãªãŸã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã®å­¦ç¿’ã‚³ãƒ¼ãƒã§ã™ã€‚

ç›´è¿‘{recent_n}å•:
{recent.to_csv()}

å…¨ä½“:
{total.to_csv()}

èª¤è§£ã—ã‚„ã™ã„ç‚¹ã¨ã€
æš—è¨˜é‡è¦–ã‹ç†è§£é‡è¦–ã‹ã‚’
ç©ã‚„ã‹ã«è¿°ã¹ã¦ãã ã•ã„ã€‚
"""
    return hf_generate(prompt, max_tokens=600, temperature=0.2)


def get_ai_final_coaching_message(df):
    total = len(df)
    correct = df["is_correct"].sum()
    rate = correct / total

    stats = df.groupby("topic").agg(æ­£è§£æ•°=("is_correct", "sum"), å›ç­”æ•°=("id", "count"))

    prompt = f"""
ä»¥ä¸‹ã¯å­¦ç¿’çµæœã§ã™ã€‚

ç·å›ç­”æ•°: {total}
æ­£è§£æ•°: {correct}
æ­£ç­”ç‡: {rate:.0%}

åˆ†é‡åˆ¥:
{stats.to_csv()}

å‰å‘ãã§ç¶™ç¶šæ„æ¬²ãŒé«˜ã¾ã‚‹
ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚
"""
    return hf_generate(prompt, max_tokens=700, temperature=0.3)


# =====================================================
# UI / mainï¼ˆå¤‰æ›´ãªã—ï¼‰
# =====================================================

def main():
    st.set_page_config("AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª")
    st.title("ğŸ“š AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª")
    init_db()
    st.info("Gemma (Hugging Face Inference API) ä½¿ç”¨ä¸­")

if __name__ == "__main__":
    main()
